# @package _global_
OPTIMIZER:
  CLASS_NAME: torch.optim.AdamW
  PARAMS:
    lr: ${TRAIN.LR}
    weight_decay: 0.001
    # decoder_lr: 0.01
